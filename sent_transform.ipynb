{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = F.normalize(a, p=2, dim=1)\n",
    "    b_norm = F.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "\n",
    "def mnr_loss(embeddings, scale=20.0):\n",
    "    B, _ = embeddings.size()\n",
    "    embeddings_a, embeddings_b = embeddings.split(B // 2, dim=0)\n",
    "    scores = cosine_similarity(embeddings_a, embeddings_b) * scale\n",
    "    labels = torch.tensor(\n",
    "        range(len(scores)), dtype=torch.long, device=scores.device\n",
    "    )  # Example a[i] should match with b[i]\n",
    "\n",
    "    return F.cross_entropy(scores, labels)\n",
    "\n",
    "\n",
    "def get_negative_mask(batch_size):\n",
    "    negative_mask = torch.ones((batch_size, 2 * batch_size), dtype=bool)\n",
    "    for i in range(batch_size):\n",
    "        negative_mask[i, i] = 0\n",
    "        negative_mask[i, i + batch_size] = 0\n",
    "\n",
    "    negative_mask = torch.cat((negative_mask, negative_mask), 0)\n",
    "    return negative_mask\n",
    "\n",
    "\n",
    "def hard_negative_loss(out, tau_plus=0.1, beta=0.5, temperature=0.07):\n",
    "    batch_size = out.size(0)// 2\n",
    "    out = F.normalize(out, p=2, dim=1)\n",
    "    out_1, out_2 = out.split(batch_size, dim=0)\n",
    "    \n",
    "    # neg score\n",
    "    neg = torch.exp(torch.mm(out, out.transpose(0, 1)) / temperature)\n",
    "    mask = get_negative_mask(batch_size).to(device)\n",
    "    neg = neg.masked_select(mask).view(2 * batch_size, -1)\n",
    "\n",
    "    # pos score\n",
    "    pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "    pos = torch.cat([pos, pos], dim=0)\n",
    "    \n",
    "\n",
    "    N = batch_size * 2 - 2\n",
    "    imp = (beta* neg.log()).exp()\n",
    "    reweight_neg = (imp*neg).sum(dim = -1) / imp.mean(dim = -1)\n",
    "    Ng = (-tau_plus * N * pos + reweight_neg) / (1 - tau_plus)\n",
    "    # constrain (optional)\n",
    "    Ng = torch.clamp(Ng, min = N * np.e**(-1 / temperature))\n",
    "\n",
    "        \n",
    "    # contrastive loss\n",
    "    loss = (- torch.log(pos / (pos + Ng) )).mean()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SentenceEncoder, Bert, BertConfig\n",
    "from tokenizer import tokenizer\n",
    "\n",
    "base_model = Bert(BertConfig()).load_model(\"data/chotot/new_ckpt.pt\", \"cpu\")\n",
    "model = SentenceEncoder(base_model, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/binhnguyenduc/Documents/1 Projects/llms/sentbert/augmented_street_dataset/cache-9e2cbdb50401850d.arrow and /Users/binhnguyenduc/Documents/1 Projects/llms/sentbert/augmented_street_dataset/cache-a415aa51bff6e9dd.arrow\n",
      "Loading cached processed dataset at /Users/binhnguyenduc/Documents/1 Projects/llms/sentbert/augmented_street_dataset/cache-b21d4a26563d7dc1.arrow\n"
     ]
    }
   ],
   "source": [
    "from transform import transform_sent\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "\n",
    "def augment(examples):\n",
    "    street_names = examples[\"street_name\"]\n",
    "    examples[\"aug_street_name\"] = [transform_sent(street_name) for street_name in street_names]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def batch_tokenized(examples):\n",
    "    return {key: [tokenizer.encode(value) for value in values] for key, values in examples.items()}\n",
    "\n",
    "\n",
    "street_dataset = load_from_disk(\"augmented_street_dataset\")\n",
    "street_datasets = street_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "train_street_dataset = street_datasets[\"train\"]\n",
    "test_street_dataset = street_datasets[\"test\"]\n",
    "tokenized_test_street_dataset = test_street_dataset.map(batch_tokenized, batched=True).rename_columns({\n",
    "    \"street_name\": \"input_ids\",\n",
    "    \"aug_street_name\": \"aug_input_ids\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def data_collator(features):\n",
    "    features = default_data_collator(features)\n",
    "    features[\"input_ids\"] = features[\"input_ids\"].to(device)\n",
    "    features[\"aug_input_ids\"] = features[\"aug_input_ids\"].to(device)\n",
    "    return features\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        return {\"input_ids\": tokenizer.encode(data[\"street_name\"]), \"aug_input_ids\": tokenizer.encode(data[\"street_name\"])}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "train_dataset = Dataset(train_street_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "test_loader = DataLoader(tokenized_test_street_dataset, batch_size=8, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938010d233ae4af78270237938dacb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16153472661972046\n",
      "0.003507960354909301\n",
      "0.003171156859025359\n",
      "0.06943691521883011\n",
      "0.0\n",
      "0.1418997347354889\n",
      "0.08032432943582535\n",
      "0.0\n",
      "0.5045386552810669\n",
      "0.0\n",
      "0.01415493618696928\n",
      "0.5202610492706299\n",
      "0.18204505741596222\n",
      "0.1247250959277153\n",
      "0.12076790630817413\n",
      "0.4917925298213959\n",
      "0.4096137285232544\n",
      "0.08454518765211105\n",
      "0.6235713362693787\n",
      "0.2646808624267578\n",
      "0.02988138236105442\n",
      "0.418828547000885\n",
      "0.1868470013141632\n",
      "0.0\n",
      "0.08570028841495514\n",
      "0.0\n",
      "0.11741338670253754\n",
      "0.08273844420909882\n",
      "0.11198565363883972\n",
      "0.4179825782775879\n",
      "0.0\n",
      "0.6560600399971008\n",
      "0.12432656437158585\n",
      "0.0\n",
      "0.6641465425491333\n",
      "0.1819010078907013\n",
      "0.0\n",
      "0.002051190473139286\n",
      "0.0\n",
      "0.1700320988893509\n",
      "0.10211546719074249\n",
      "0.12547257542610168\n",
      "0.1291946917772293\n",
      "0.07902386784553528\n",
      "0.12239798903465271\n",
      "0.6986942291259766\n",
      "0.0\n",
      "0.0\n",
      "0.04716791212558746\n",
      "0.007289530243724585\n",
      "0.06331422924995422\n",
      "0.0\n",
      "0.0\n",
      "0.03713144361972809\n",
      "0.0\n",
      "0.021734334528446198\n",
      "0.0\n",
      "0.0\n",
      "0.02637563645839691\n",
      "0.644249439239502\n",
      "0.05244774371385574\n",
      "0.06585892289876938\n",
      "0.029814869165420532\n",
      "0.048060450702905655\n",
      "0.0\n",
      "0.18496623635292053\n",
      "0.0\n",
      "0.4177253544330597\n",
      "0.014796171337366104\n",
      "0.0\n",
      "0.0\n",
      "0.039639998227357864\n",
      "0.4721006453037262\n",
      "0.0\n",
      "0.5818251371383667\n",
      "0.026550574228167534\n",
      "0.3571966290473938\n",
      "0.35880154371261597\n",
      "0.008026299066841602\n",
      "0.0\n",
      "0.20912088453769684\n",
      "0.05539809539914131\n",
      "0.11201959103345871\n",
      "0.0\n",
      "0.04720055311918259\n",
      "0.0\n",
      "0.26016438007354736\n",
      "0.0\n",
      "0.5593684911727905\n",
      "0.0018068699864670634\n",
      "0.06220783293247223\n",
      "0.0\n",
      "0.0\n",
      "0.10484687238931656\n",
      "0.09975571930408478\n",
      "0.058212146162986755\n",
      "0.036559704691171646\n",
      "0.0\n",
      "0.1172633096575737\n",
      "0.4650475084781647\n",
      "0.0\n",
      "0.0\n",
      "0.005676273722201586\n",
      "0.38433003425598145\n",
      "0.0\n",
      "0.0\n",
      "0.03080255351960659\n",
      "0.3116263151168823\n",
      "0.0\n",
      "0.19345904886722565\n",
      "0.7747977375984192\n",
      "0.022970357909798622\n",
      "0.0\n",
      "0.09435126185417175\n",
      "0.0\n",
      "0.13437484204769135\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2269362062215805\n",
      "0.01000458374619484\n",
      "0.0\n",
      "0.023310722783207893\n",
      "0.02916298434138298\n",
      "0.026071680709719658\n",
      "0.0\n",
      "0.4621710181236267\n",
      "0.03878701850771904\n",
      "0.05848177894949913\n",
      "0.21705752611160278\n",
      "0.0\n",
      "0.0\n",
      "0.03362707793712616\n",
      "0.0\n",
      "0.0\n",
      "0.31471893191337585\n",
      "0.0\n",
      "0.14167694747447968\n",
      "0.0\n",
      "0.10962527245283127\n",
      "0.0\n",
      "0.0\n",
      "0.04940471798181534\n",
      "0.23847533762454987\n",
      "0.0\n",
      "0.12372784316539764\n",
      "0.035703469067811966\n",
      "0.3825518786907196\n",
      "0.021810391917824745\n",
      "0.036553435027599335\n",
      "0.12030551582574844\n",
      "0.0\n",
      "0.04332863166928291\n",
      "0.0\n",
      "0.01374825555831194\n",
      "0.0\n",
      "0.0\n",
      "0.11929003149271011\n",
      "0.0\n",
      "0.0021937950514256954\n",
      "0.00990391243249178\n",
      "0.0\n",
      "0.18353599309921265\n",
      "0.007546450011432171\n",
      "0.0\n",
      "0.0\n",
      "0.40455180406570435\n",
      "0.01456382405012846\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0053780837915837765\n",
      "0.25621604919433594\n",
      "0.005652498919516802\n",
      "0.1471361666917801\n",
      "0.10440023243427277\n",
      "0.03944866731762886\n",
      "0.0201902873814106\n",
      "0.0775543749332428\n",
      "0.0\n",
      "0.0\n",
      "0.22645357251167297\n",
      "0.15428636968135834\n",
      "0.21654722094535828\n",
      "0.0\n",
      "0.1613701581954956\n",
      "0.12322311103343964\n",
      "0.03598536550998688\n",
      "0.09156092256307602\n",
      "0.0\n",
      "0.10841143131256104\n",
      "0.06475701928138733\n",
      "0.0\n",
      "0.25710681080818176\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.09356161206960678\n",
      "0.32958951592445374\n",
      "0.0\n",
      "0.0\n",
      "0.07067140191793442\n",
      "0.0\n",
      "0.0\n",
      "0.1045738235116005\n",
      "0.2926520109176636\n",
      "0.3139062523841858\n",
      "0.0\n",
      "0.07760091125965118\n",
      "0.14989237487316132\n",
      "0.10619840025901794\n",
      "0.0\n",
      "0.300689697265625\n",
      "0.0\n",
      "0.03114084154367447\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05139661580324173\n",
      "0.0\n",
      "0.08531899750232697\n",
      "0.013793795369565487\n",
      "0.0\n",
      "0.0\n",
      "0.054164204746484756\n",
      "0.0\n",
      "0.04469498246908188\n",
      "0.03793948143720627\n",
      "0.0\n",
      "0.5960479378700256\n",
      "0.05587410181760788\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014317402616143227\n",
      "0.0\n",
      "0.3438948392868042\n",
      "0.0\n",
      "0.45869600772857666\n",
      "0.04586991295218468\n",
      "0.0\n",
      "0.06443418562412262\n",
      "0.027690574526786804\n",
      "0.0\n",
      "0.0\n",
      "0.012007839046418667\n",
      "0.02237151563167572\n",
      "0.0\n",
      "0.0\n",
      "0.016062607988715172\n",
      "0.0\n",
      "0.24945303797721863\n",
      "0.008578317239880562\n",
      "0.13876208662986755\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.14565491676330566\n",
      "0.1993267834186554\n",
      "0.0\n",
      "0.0\n",
      "0.035790883004665375\n",
      "0.0\n",
      "0.004597301594913006\n",
      "0.06077447161078453\n",
      "0.0\n",
      "0.07625149935483932\n",
      "0.0\n",
      "0.0\n",
      "0.28322523832321167\n",
      "0.0\n",
      "0.0\n",
      "0.024613458663225174\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006405981257557869\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m model(input_ids)\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m hard_negative_loss(embeddings)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "ctx = nullcontext()\n",
    "epochs = 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in trange(epochs):\n",
    "    for inputs in train_loader:\n",
    "        inputs_1 = inputs[\"input_ids\"]\n",
    "        inputs_2 = inputs[\"aug_input_ids\"]\n",
    "        input_ids = torch.concat([inputs_1, inputs_2], dim=0)\n",
    "        with ctx:\n",
    "            embeddings = model(input_ids)\n",
    "            loss = hard_negative_loss(embeddings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = hard_negative_loss(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2057, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = embeddings\n",
    "batch_size = out.size(0)// 2\n",
    "out_1, out_2 = out.split(batch_size, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.07\n",
    "neg = torch.exp(cosine_similarity(out, out) / temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1600327.6250,  162046.5312,   75902.3984,  195953.3125,   21770.0996,\n",
       "          145809.0000,  160701.6250,  191996.0000, 1126005.5000,  165599.6250,\n",
       "           59242.7656,  115989.0469,   10814.1572,  106603.7344,  151332.7812,\n",
       "          177264.5781],\n",
       "        [ 162046.5312, 1600326.0000,   41476.6133,   47023.9961,    6186.6689,\n",
       "          224424.9688,   82642.0000,   32690.5762,  131124.9531, 1240143.7500,\n",
       "           27722.5234,   30601.1113,    3059.5376,  136082.9844,   90919.4609,\n",
       "           48464.7188],\n",
       "        [  75902.3984,   41476.6133, 1600323.0000,   54524.0859,   15670.7861,\n",
       "           50957.6836,  135132.5625,   25715.7910,   75110.9609,   45155.6523,\n",
       "          993864.0625,   53095.4023,    8681.9893,   37372.3906,  114471.0234,\n",
       "           23520.1953],\n",
       "        [ 195953.3125,   47023.9961,   54524.0859, 1600327.6250,   42133.5117,\n",
       "          119657.9297,  371280.7188,  195052.5938,  156048.6250,   43597.9727,\n",
       "           37018.2383, 1055215.0000,   27179.1406,   92970.4297,  342614.0625,\n",
       "          182461.7812],\n",
       "        [  21770.0996,    6186.6689,   15670.7861,   42133.5117, 1600327.6250,\n",
       "           18163.7695,   24721.0605,   42256.8477,   31044.9414,    5556.9814,\n",
       "           10563.6270,   42557.3359, 1078041.5000,   16215.7607,   21763.9336,\n",
       "           49786.7930],\n",
       "        [ 145809.0000,  224424.9688,   50957.6836,  119657.9297,   18163.7695,\n",
       "         1600326.0000,   98156.8281,  100004.2578,  127276.9688,  211191.5781,\n",
       "           38145.0547,   92198.5547,    9765.5576, 1030827.9375,  100052.3359,\n",
       "          133189.2344],\n",
       "        [ 160701.6250,   82642.0000,  135132.5625,  371280.7188,   24721.0605,\n",
       "           98156.8281, 1600320.0000,  105506.8516,  126866.7578,   78136.5625,\n",
       "          103957.4375,  316521.0000,   13178.0283,   88714.6953, 1089374.7500,\n",
       "          116477.3359],\n",
       "        [ 191996.0000,   32690.5762,   25715.7910,  195052.5938,   42256.8477,\n",
       "          100004.2578,  105506.8516, 1600323.0000,  175187.1875,   34001.6719,\n",
       "           16947.4570,  165194.7188,   23920.6094,   95860.5391,   79517.1953,\n",
       "         1049868.8750],\n",
       "        [1126005.5000,  131124.9531,   75110.9609,  156048.6250,   31044.9414,\n",
       "          127276.9688,  126866.7578,  175187.1875, 1600323.0000,  131160.7188,\n",
       "           61534.6758,   94278.2031,   15471.4014,   98574.5625,  117643.9375,\n",
       "          152422.7188],\n",
       "        [ 165599.6250, 1240143.7500,   45155.6523,   43597.9727,    5556.9814,\n",
       "          211191.5781,   78136.5625,   34001.6719,  131160.7188, 1600323.0000,\n",
       "           32355.7266,   29371.5195,    2829.6274,  124188.5312,   83278.0156,\n",
       "           50895.5156],\n",
       "        [  59242.7656,   27722.5234,  993864.0625,   37018.2383,   10563.6270,\n",
       "           38145.0547,  103957.4375,   16947.4570,   61534.6758,   32355.7266,\n",
       "         1600316.8750,   32443.0762,    5479.6533,   30848.0312,   88161.3359,\n",
       "           18167.1484],\n",
       "        [ 115989.0469,   30601.1113,   53095.4023, 1055215.0000,   42557.3359,\n",
       "           92198.5547,  316521.0000,  165194.7188,   94278.2031,   29371.5195,\n",
       "           32443.0762, 1600315.3750,   32877.2930,   79444.9609,  291346.0000,\n",
       "          139767.0781],\n",
       "        [  10814.1572,    3059.5376,    8681.9893,   27179.1406, 1078041.5000,\n",
       "            9765.5576,   13178.0283,   23920.6094,   15471.4014,    2829.6274,\n",
       "            5479.6533,   32877.2930, 1600323.0000,    8834.4014,   10795.0645,\n",
       "           25571.3066],\n",
       "        [ 106603.7344,  136082.9844,   37372.3906,   92970.4297,   16215.7607,\n",
       "         1030827.9375,   88714.6953,   95860.5391,   98574.5625,  124188.5312,\n",
       "           30848.0312,   79444.9609,    8834.4014, 1600327.6250,   85392.9297,\n",
       "          129459.9375],\n",
       "        [ 151332.7812,   90919.4609,  114471.0234,  342614.0625,   21763.9336,\n",
       "          100052.3359, 1089374.7500,   79517.1953,  117643.9375,   83278.0156,\n",
       "           88161.3359,  291346.0000,   10795.0645,   85392.9297, 1600323.0000,\n",
       "           98791.5859],\n",
       "        [ 177264.5781,   48464.7188,   23520.1953,  182461.7812,   49786.7930,\n",
       "          133189.2344,  116477.3359, 1049868.8750,  152422.7188,   50895.5156,\n",
       "           18167.1484,  139767.0781,   25571.3066,  129459.9375,   98791.5859,\n",
       "         1600327.6250]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = get_negative_mask(batch_size).to(device)\n",
    "neg = neg.masked_select(mask).view(2 * batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # pos score\n",
    "        pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "        pos = torch.cat([pos, pos], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        mask = get_negative_mask(batch_size).to(device)\n",
    "        neg = neg.masked_select(mask).view(2 * batch_size, -1)\n",
    "\n",
    "        # pos score\n",
    "        pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "        pos = torch.cat([pos, pos], dim=0)\n",
    "        \n",
    "\n",
    "        N = batch_size * 2 - 2\n",
    "        imp = (beta* neg.log()).exp()\n",
    "        reweight_neg = (imp*neg).sum(dim = -1) / imp.mean(dim = -1)\n",
    "        Ng = (-tau_plus * N * pos + reweight_neg) / (1 - tau_plus)\n",
    "        # constrain (optional)\n",
    "        Ng = torch.clamp(Ng, min = N * np.e**(-1 / temperature))\n",
    "\n",
    "            \n",
    "        # contrastive loss\n",
    "        loss = (- torch.log(pos / (pos + Ng) )).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batch_size = out.size(0)// 2\n",
    "    out_1, out_2 = out.split(batch_size, dim=0)\n",
    "    \n",
    "    # neg score\n",
    "    neg = torch.exp(cosine_similarity(out, out) / temperature)\n",
    "    old_neg = neg.clone()\n",
    "    mask = get_negative_mask(batch_size).to(device)\n",
    "    neg = neg.masked_select(mask).view(2 * batch_size, -1)\n",
    "\n",
    "    # pos score\n",
    "    pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "    pos = torch.cat([pos, pos], dim=0)\n",
    "    \n",
    "\n",
    "    N = batch_size * 2 - 2\n",
    "    imp = (beta* neg.log()).exp()\n",
    "    reweight_neg = (imp*neg).sum(dim = -1) / imp.mean(dim = -1)\n",
    "    Ng = (-tau_plus * N * pos + reweight_neg) / (1 - tau_plus)\n",
    "    # constrain (optional)\n",
    "    Ng = torch.clamp(Ng, min = N * np.e**(-1 / temperature))\n",
    "\n",
    "        \n",
    "    # contrastive loss\n",
    "    loss = (- torch.log(pos / (pos + Ng) )).mean()\n",
    "\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
